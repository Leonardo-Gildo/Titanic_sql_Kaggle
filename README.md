# 🚢 Titanic SQL Kaggle - Projeto de Estudo

Este repositório documenta minha evolução no aprendizado de **SQL Server, Docker e Análise de Dados**, aplicados ao desafio **[Titanic - Machine Learning from Disaster](https://www.kaggle.com/c/titanic)**.

---

## 📌 Objetivos do Projeto
- Consolidar fundamentos de **SQL Server** (SSMS e Azure Data Studio).  
- Aprender a usar **Docker** como ambiente de banco de dados.  
- Trabalhar com **importação, limpeza e transformação** de dados.  
- Criar **consultas SQL** para exploração dos dados.  
- Submeter previsões ao Kaggle para entender o fluxo de uma competição de dados.  

---

## 🛠️ Tecnologias Utilizadas
- SQL Server 2022 (local e via Docker)  
- SQL Server Management Studio (SSMS)  
- Azure Data Studio (ADS)  
- Git + GitHub para versionamento  
- Kaggle (competição Titanic)  

---

## 📂 Estrutura do Repositório
```
titanic-sql-kaggle/
│
├── sql/                # Scripts SQL (criação de tabelas, limpeza, consultas, submissão Kaggle)
├── data/               # Instruções para download dos datasets originais
│   └── README.md
├── submissions/        # Arquivos gerados para submissão no Kaggle
├── README.md           # Documentação em Português
└── README_EN.md        # Documentation in English
```
📈 Minha Evolução

Configuração do ambiente

Instalação do SQL Server no Windows.

Criação de container Docker com SQL Server 2022.

Conexão usando SSMS e ADS.

Importação de dados

Importação dos arquivos train.csv, test.csv e gender_submission.csv.

Criação de tabelas staging e tabelas clean.

Exploração dos dados (SQL Queries)

Consultas simples (contagem, médias, agrupamentos).

Exercícios práticos para consolidar SQL.

Submissão no Kaggle

Geração do submission.csv usando SQL.

Upload no Kaggle e primeira pontuação validada.

🚀 Próximos Passos

Criar mais consultas exploratórias.

Avançar para Python + Pandas para complementar análise.

Explorar técnicas de Machine Learning para melhorar a pontuação no Kaggle.

👤 Autor

Projeto desenvolvido por Leonardo Gildo como parte de sua jornada para se tornar Analista de Dados / DBA.

📬 Contato
